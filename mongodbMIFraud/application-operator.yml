# --------------------------
# SAMPLE CONFIGURATION
# --------------------------

spring:
  data:
    mongodb:
      username: ${TEAM25_MONGODB_MONGO_USER:admin}
      password: ${TEAM25_MONGODB_MONGO_PASSWORD:secret}
      host: ${TEAM25_MONGODB_MONGO_HOST:localhost}
      port: ${TEAM25_MONGODB_MONGO_PORT}
      authentication-database: admin
      database: ${TEAM25_MONGODB_MONGO_DB}
  cloud:

    # For more info about Spring Cloud Stream and the Solace PubSub+ binder:
    # - https://docs.spring.io/spring-cloud-stream/docs/current/reference/html/spring-cloud-stream.html
    # - https://github.com/SolaceProducts/solace-spring-cloud/tree/master/solace-spring-cloud-starters/solace-spring-cloud-stream-starter
    stream:
      bindings:  # Workflow bindings
        input-0:
          destination: "mongodb:mongodb" # Queue name mongodb?database=test&collection=user&operation=findAll
          binder: camel
        output-0:
          destination: mongodb/source  #test/camel/mongodb # mongodb producer destination
          binder: solace
        input-1:
          destination: ${SOLACE_QUEUE} # mongodb consumer destination
          binder: solace
          consumer:
            #Concurrency can be used with a consumer group (non-exclusive queue) to process events in multiple threads
            batch-mode: true
            concurrency: 1
        output-1:
          destination: "mongodb:mongodb"  # Topic name?database=test&collection=user&operation=insert
          binder: camel

      solace:
        bindings:
          input-1:
            consumer:
              batchMaxSize: 2000
              batchTimeout: 5000
              provisionSubscriptionsToDurableQueue: false
              provisionDurableQueue: false
              queueNamePrefix: ""
              useFamiliarityInQueueName: false
              useDestinationEncodingInQueueName: false
              useGroupNameInQueueName: false

      camel:
        bindings:
          input-0:
            consumer:
              endpoint:
                query-parameters:
                  database: ${TEAM25_MONGODB_MONGO_DB}
                  collection:  users
#                  consumerType: changestreams
                  tailTrackIncreasingField: _id        #sequatial column of source connection
                  persistentTailTracking: true
                  persistentId: workflow0              #unique for each collection
                  tailTrackDb: trackers              #default as same db
                  tailTrackCollection: camelTrackers  #default camelTailTracking
                  tailTrackField: lastProcessedkey
                  #default as cancellationsTracker
##                  operation: findAll

          output-1:
            producer:
              endpoint:
                query-parameters:
                  database: ${TEAM25_MONGODB_MONGO_DB}
                  collection: ${TEAM25_MONGODB_MONGO_COLLECTION}
                  operation:  bulkWrite         #save,bulkWrite

solace:
  connector:
    workflows:  # Workflow configuration
      0:
        enabled: false  # If true, the workflow is enabled.d
        #transform-headers: # Per-Processor headers transform configuration
          #expressions: # A mapping of header names to header value SpEL expressions. The SpEL context contains the `headers` parameter which can be used to read the input message’s headers.
            # scst_targetDestination: "T(String).format('%s', headers.get('solace_replyTo').getName().toString())"
            #scst_targetDestination: "T(String).format('mongo/event/%s', payload.get('color').toString())"
      1:
        enabled: true  # If true, the workflow is enabled.

    #        transform-headers:  # Per-Processor headers transform configuration
    #          expressions:  # A mapping of header names to header value SpEL expressions. The SpEL context contains the `headers` parameter which can be used to read the input message’s headers.
    #            new-header: "'prefix-' + headers.id"  # Example
    #        transform-payloads:  # Per-Processor payloads transform configuration
    #          expressions:  # A list of a single transformation as a SpEL expression
    #            - transform: "#isPayloadBytes(payload) ? new String(payload).toUpperCase() : payload instanceof T(String) ? payload.toUpperCase() : payload"  # Example

    #    management:
    #      leader-election:
    #        mode: standalone  # The connector’s leader election mode. (values: standalone, active_active, active_standby)
    #        fail-over:
    #          max-attempts: 3  # The maximum number of attempts to perform a fail-over.
    #          back-off-initial-interval: 1000  # The initial interval (milliseconds) to back-off when retrying a fail-over.
    #          back-off-max-interval: 10000  # The maximum interval (milliseconds) to back-off when retrying a fail-over.
    #          back-off-multiplier: 2.0  # The multiplier to apply to the back-off interval between each retry of a fail-over.
    #      queue: management-queue  # The management queue name.
    #      session:  # The management session. This has the same interface as that used by `solace.java.*`. For more info: https://github.com/SolaceProducts/solace-spring-boot/tree/master/solace-spring-boot-starters/solace-java-spring-boot-starter#updating-your-application-properties
    #        host: tcp://localhost:55555
    #        client-username: default
    #        client-password: default

    security:
      enabled: true  # If true, security is enabled. Otherwise, anyone has access to the connector's endpoints.
      csrf-enabled: true  # If true, CSRF protection is enabled. Makes sense only if solace.connector.security.enabled is true.
  #      users:  # User configuration. To access endpoints when security is enabled, at least one user must be created.
  #        - name:   # The name of this user.
  #          password: # The password for this user.
  #          roles:  # The list of roles which this user has. Has read-only access if no roles are given. (values: admin)
  #            - admin


  java:  # Solace PubSub+ connection details. For more info: https://github.com/SolaceProducts/solace-spring-boot/tree/master/solace-spring-boot-starters/solace-java-spring-boot-starter#updating-your-application-properties
    connect-retries: -1
    reconnect-retries: -1
    host: ${SOLACE_BROKER_SMF_URL:tcp://localhost:55554}
    msgVpn: ${SOLACE_BROKER_VPN:default}
    clientUsername: ${SOLACE_BROKER_USERNAME:admin}
    clientPassword: ${SOLACE_BROKER_PASSWORD:secret}

management:
  metrics:  # Metrics monitoring systems. For more info: https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html#actuator.metrics
    export:
      #      defaults:
      #        enabled: false
      simple:
        enabled: true
  #      <system>:
  #        enabled: false
  #  endpoint:
  #    health:
  #      show-components: never
  #      show-details: never
  endpoints:
    web:  # Actuator web endpoint configuration. For more info: https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html#actuator.endpoints. Initial set of metrics is defined as a bare minimum for Connector Manager compatibility. To shrink it simply remove unnecessary ones
      exposure:
        include: "health,metrics,loggers,logfile,channels,env,workflows,leaderelection,bindings"
        exclude: "diskSpace,mappings"

logging:  # Logging configuration. For more info: https://docs.spring.io/spring-boot/docs/current/reference/html/features.html#features.logging
  level:
    root: info
    com.solace.connector.mongodb: info # Enables logs for connector
    com.solace.connector.core: info # Enables logs for connector framework
    com.solace.spring.cloud.stream.binder: WARN # Enables logs for Solace and JMS binders
  file:
    name: myapp.log  # base log file name. Example: Generates a log file to a file named myapp.log.
  logback:
    rollingpolicy:  # Logback file rolling policy
      file-name-pattern: "${LOG_FILE}.%d{yyyy-MM-dd}.%i.gz"  # Pattern for rolled-over log file names. Example: Rolls the log file into an archive once every day. `%i` is reset to `0` at the start of the day.
      max-file-size: 100MB  # The maximum size of log file before it is archived. Example: Within a given day, when the log file reaches 100 MB, archive it, and increment `%i`.
      max-history: 7  # The maximum rotation-period's worth of archive log files to keep. Example: Since the `file-name-pattern` is configured to rollover once every day, keep 7 days worth of log archives.
      total-size-cap: 1GB  # Total size of log backups for a given rotation period. Example: Keep up-to 1 GB of log archives for every day.

server:
  port: 8299
